# ü§ñ Sistema ML Predictor de YouTube

Sistema de Machine Learning 100% autom√°tico para predecir el rendimiento (VPH) de videos ANTES de publicarlos.

## üìã Tabla de Contenidos

- [Arquitectura del Sistema](#arquitectura-del-sistema)
- [Componentes](#componentes)
- [Flujo de Datos](#flujo-de-datos)
- [Instalaci√≥n](#instalaci√≥n)
- [Uso](#uso)
- [Automatizaci√≥n](#automatizaci√≥n)
- [M√©tricas y Validaci√≥n](#m√©tricas-y-validaci√≥n)
- [Anti-Patrones](#anti-patrones)
- [Troubleshooting](#troubleshooting)

---

## üèóÔ∏è Arquitectura del Sistema

### Estrategia H√≠brida

El sistema usa un enfoque h√≠brido de dos niveles:

1. **SEMANAL** (Domingos 3AM):
   - An√°lisis ligero de anti-patrones
   - Detecta qu√© fall√≥ en videos de la semana
   - **NO** re-entrena el modelo
   - Tiempo: ~1 minuto
   - Cuota API: 0 unidades

2. **MENSUAL** (D√≠a 1 de cada mes):
   - Snapshot de datos antes de purgar
   - Re-entrenamiento completo del modelo
   - Validaci√≥n estricta (Precision >= 60%, R¬≤ >= 0.20)
   - Tiempo: ~10 minutos
   - Cuota API: 0 unidades

### ¬øPor Qu√© H√≠brido?

| Aspecto | Solo Semanal | Solo Mensual | **H√≠brido** |
|---------|--------------|--------------|-------------|
| Alertas r√°pidas | ‚úÖ | ‚ùå | ‚úÖ |
| Evita overfitting | ‚ùå | ‚úÖ | ‚úÖ |
| Adapta a cambios | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚úÖ |
| Consumo recursos | Bajo | Medio | √ìptimo |

---

## üì¶ Componentes

### 1. Base de Datos (Supabase)

#### Tablas ML

```sql
-- Datos de entrenamiento (NUNCA se purgan)
ml_training_data
‚îú‚îÄ‚îÄ video_id (PK)
‚îú‚îÄ‚îÄ es_tuyo (boolean) -- TRUE = tu canal, FALSE = competencia
‚îú‚îÄ‚îÄ title, duration, category_id, channel_subscribers
‚îú‚îÄ‚îÄ vph (target principal)
‚îú‚îÄ‚îÄ nicho_score
‚îî‚îÄ‚îÄ snapshot_date

-- Metadata de modelos entrenados
modelo_ml_metadata
‚îú‚îÄ‚îÄ id (PK)
‚îú‚îÄ‚îÄ version (ej: "2025.01")
‚îú‚îÄ‚îÄ precision, r2_mean, dataset_size
‚îú‚îÄ‚îÄ features_usadas
‚îî‚îÄ‚îÄ trained_at

-- Anti-patrones detectados
anti_patrones
‚îú‚îÄ‚îÄ id (PK)
‚îú‚îÄ‚îÄ patron (ej: "Publicar lunes ma√±ana")
‚îú‚îÄ‚îÄ frecuencia (cu√°ntas veces detectado)
‚îú‚îÄ‚îÄ confianza (BAJA/MEDIA/ALTA)
‚îî‚îÄ‚îÄ impacto_vph_promedio
```

#### Crear Tablas

```bash
cd sql
psql $SUPABASE_URL -f create_ml_training_data.sql
```

### 2. Scripts Python

```
scripts/
‚îú‚îÄ‚îÄ save_training_snapshot.py     # Guarda datos antes de purgar
‚îú‚îÄ‚îÄ train_predictor_model.py      # Entrenamiento mensual
‚îú‚îÄ‚îÄ analizar_anti_patrones_semanal.py  # An√°lisis semanal
‚îú‚îÄ‚îÄ predict_video.py              # Predicci√≥n individual
‚îî‚îÄ‚îÄ nicho_utils.py                # Utilidades compartidas
```

### 3. Modelos ML

```
models/
‚îî‚îÄ‚îÄ predictor_ensemble.pkl        # Ensemble de 3 modelos
    ‚îú‚îÄ‚îÄ Random Forest (40% peso)
    ‚îú‚îÄ‚îÄ Gradient Boosting (40% peso)
    ‚îî‚îÄ‚îÄ Ridge Regression (20% peso)
```

### 4. Workflows GitHub Actions

```
.github/workflows/
‚îú‚îÄ‚îÄ ml_system.yml                 # An√°lisis semanal
‚îú‚îÄ‚îÄ ml_monthly_training.yml       # Entrenamiento mensual
‚îú‚îÄ‚îÄ purga_automatica_supabase.yml # Con snapshot integrado
‚îî‚îÄ‚îÄ search_trending_every_2days.yml  # Con snapshot integrado
```

### 5. Dashboard Local

```
dashboard_predictor.html          # Interfaz web local
```

---

## üîÑ Flujo de Datos

### 1. Captura de Datos

```
fetch_shorts_search.py ‚îÄ‚îÄ‚îê
fetch_explosive_longs.py ‚îÄ‚î§
fetch_trending_videos.py ‚îÄ‚îº‚îÄ‚îÄ> Supabase Tables
maint_metrics.py ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     (video_shorts_search,
                                 video_explosive_longs,
                                 video_trending)
```

### 2. Snapshot Pre-Purga

```
Cada 2 d√≠as (antes de purgar):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ save_training_snapshot.py           ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Videos 23-30 d√≠as (competencia) ‚îÇ ‚îÇ
‚îÇ ‚îÇ Videos 173-180 d√≠as (tuyos)     ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                     ‚îÇ
‚îÇ      ml_training_data (permanente) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
   purga_trending_30dias.py
   (elimina videos >30 d√≠as)
```

### 3. Entrenamiento Mensual

```
D√≠a 1 de cada mes:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ train_predictor_model.py             ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ 1. Load √∫ltimos 6 meses          ‚îÇ ‚îÇ
‚îÇ ‚îÇ 2. Extract 12 features           ‚îÇ ‚îÇ
‚îÇ ‚îÇ 3. Train ensemble (RF+GB+Ridge)  ‚îÇ ‚îÇ
‚îÇ ‚îÇ 4. Validate (TimeSeriesSplit)    ‚îÇ ‚îÇ
‚îÇ ‚îÇ 5. Check: Precision >= 60%?      ‚îÇ ‚îÇ
‚îÇ ‚îÇ    ‚îî‚îÄ S√ç: Guardar modelo         ‚îÇ ‚îÇ
‚îÇ ‚îÇ    ‚îî‚îÄ NO: Mantener anterior      ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
   predictor_ensemble.pkl
   (commit a GitHub)
```

### 4. An√°lisis Semanal

```
Cada domingo 3AM:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ analizar_anti_patrones_semanal.py    ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ 1. Get videos √∫ltimos 7 d√≠as     ‚îÇ ‚îÇ
‚îÇ ‚îÇ 2. Clasificar (√âXITO/PROMEDIO/   ‚îÇ ‚îÇ
‚îÇ ‚îÇ    FRACASO) por VPH              ‚îÇ ‚îÇ
‚îÇ ‚îÇ 3. Analizar solo FRACASOS:       ‚îÇ ‚îÇ
‚îÇ ‚îÇ    - Timing (d√≠a/hora)           ‚îÇ ‚îÇ
‚îÇ ‚îÇ    - T√≠tulo (gancho, a√±o, etc.)  ‚îÇ ‚îÇ
‚îÇ ‚îÇ    - Nicho (score)               ‚îÇ ‚îÇ
‚îÇ ‚îÇ 4. Save to anti_patrones table   ‚îÇ ‚îÇ
‚îÇ ‚îÇ 5. Generate report (email)       ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5. Predicci√≥n

```
Usuario:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ python predict_video.py              ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Input: t√≠tulo, duraci√≥n, timing  ‚îÇ ‚îÇ
‚îÇ ‚îÇ   ‚Üì                              ‚îÇ ‚îÇ
‚îÇ ‚îÇ Extract 12 features              ‚îÇ ‚îÇ
‚îÇ ‚îÇ   ‚Üì                              ‚îÇ ‚îÇ
‚îÇ ‚îÇ Load predictor_ensemble.pkl      ‚îÇ ‚îÇ
‚îÇ ‚îÇ   ‚Üì                              ‚îÇ ‚îÇ
‚îÇ ‚îÇ Predict VPH                      ‚îÇ ‚îÇ
‚îÇ ‚îÇ   ‚Üì                              ‚îÇ ‚îÇ
‚îÇ ‚îÇ Classify: EXITOSO/PROMEDIO/      ‚îÇ ‚îÇ
‚îÇ ‚îÇ           FRACASO                ‚îÇ ‚îÇ
‚îÇ ‚îÇ   ‚Üì                              ‚îÇ ‚îÇ
‚îÇ ‚îÇ Generate recommendations         ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ Instalaci√≥n

### 1. Dependencias Python

```bash
pip install -r requirements.txt

# Dependencias ML adicionales:
pip install scikit-learn==1.3.0
pip install pandas numpy
```

### 2. Crear Tablas en Supabase

```bash
cd sql
# Copiar contenido de create_ml_training_data.sql
# Ejecutar en Supabase SQL Editor
```

O usando CLI:

```bash
psql $SUPABASE_URL -f create_ml_training_data.sql
```

### 3. Verificar GitHub Secrets

Asegurar que existen:

```
SUPABASE_URL
SUPABASE_SERVICE_KEY
YT_REFRESH_TOKEN
YT_CLIENT_ID
YT_CLIENT_SECRET
```

### 4. Test Manual

```bash
cd scripts

# Test 1: Snapshot
python save_training_snapshot.py

# Test 2: An√°lisis semanal (requiere videos de √∫ltima semana)
python analizar_anti_patrones_semanal.py

# Test 3: Entrenamiento (requiere >= 100 videos en ml_training_data)
python train_predictor_model.py

# Test 4: Predicci√≥n
python predict_video.py
```

---

## üíª Uso

### Predicci√≥n Individual (CLI)

#### Modo Interactivo

```bash
cd scripts
python predict_video.py
```

Te pedir√°:
- T√≠tulo del video
- Duraci√≥n (segundos)
- D√≠a de publicaci√≥n
- Hora de publicaci√≥n
- Score de nicho (opcional, default: 70)

#### Modo Argumentos

```bash
python predict_video.py \
  --titulo "SECRETO de ChatGPT 2025 que NADIE conoce" \
  --duracion 300 \
  --dia viernes \
  --hora 18 \
  --nicho-score 75
```

Salida:

```
==================================================
PREDICCI√ìN
==================================================

T√≠tulo: SECRETO de ChatGPT 2025 que NADIE conoce
Duraci√≥n: 300s (5m 0s)
Timing: Viernes a las 18:00

VPH PREDICHO: 127.3
CLASIFICACI√ìN: EXITOSO üöÄ

üéâ ¬°Excelente! Este video tiene alto potencial
   Recomendado PUBLICAR

==================================================
RECOMENDACIONES
==================================================
‚úÖ Video cumple con todas las mejores pr√°cticas
==================================================
```

### Dashboard Web Local

Abre en navegador:

```bash
# En Windows
start dashboard_predictor.html

# En Mac/Linux
open dashboard_predictor.html
```

**IMPORTANTE**: El dashboard usa predicciones simuladas. Para predicciones REALES del modelo entrenado, usa `predict_video.py`.

---

## ‚öôÔ∏è Automatizaci√≥n

### Cronograma Completo

| Frecuencia | Workflow | Script | Hora | Descripci√≥n |
|------------|----------|--------|------|-------------|
| **Cada 2 d√≠as** | search_trending_every_2days.yml | save_training_snapshot.py | 6AM | Snapshot competencia antes de purgar |
| **Cada 2 d√≠as** | search_trending_every_2days.yml | purga_trending_30dias.py | 6AM | Purga videos trending >30 d√≠as |
| **Domingos** | ml_system.yml | analizar_anti_patrones_semanal.py | 3AM | An√°lisis de anti-patrones |
| **D√≠a 1 mes** | purga_automatica_supabase.yml | save_training_snapshot.py | 3AM | Snapshot videos propios antes de purgar |
| **D√≠a 1 mes** | purga_automatica_supabase.yml | purga_inteligente_supabase.py | 3AM | Purga videos propios >180 d√≠as |
| **D√≠a 1 mes** | ml_monthly_training.yml | train_predictor_model.py | 2AM | Re-entrenamiento modelo ML |

### Flujo Mensual Completo

```
D√≠a 28-30: Snapshot de competencia (cada 2 d√≠as)
    ‚Üì
D√≠a 1, 3AM: Snapshot de videos propios
    ‚Üì
D√≠a 1, 3AM: Purga inteligente (elimina >180 d√≠as)
    ‚Üì
D√≠a 1, 2AM: Entrenamiento modelo ML
    ‚Üì
D√≠a 1, 2AM: Commit modelo a GitHub
```

### Triggers Manuales

Todos los workflows se pueden ejecutar manualmente:

1. Ir a GitHub ‚Üí Actions
2. Seleccionar workflow
3. Click "Run workflow"
4. Seleccionar opciones (si aplica)

---

## üìä M√©tricas y Validaci√≥n

### Features Usadas (12 Total)

El modelo usa solo 12 features limpias para evitar overfitting:

| # | Feature | Tipo | Descripci√≥n |
|---|---------|------|-------------|
| 1 | `nicho_score_norm` | Continua | Score de nicho normalizado (0-1) |
| 2 | `es_nicho_core` | Binaria | Score >= 60 |
| 3 | `dia_tipo` | Categ√≥rica | 0=weekday, 1=viernes, 2=weekend |
| 4 | `hora_tipo` | Categ√≥rica | 0=other, 1=afternoon(14-17h), 2=prime(17-21h) |
| 5 | `es_short` | Binaria | Duraci√≥n < 90s |
| 6 | `duracion_optima` | Binaria | 20-60s (short) o 180-600s (long) |
| 7 | `titulo_len_cat` | Categ√≥rica | 0=<60, 1=60-80, 2=>80 chars |
| 8 | `tiene_gancho` | Binaria | Contiene SECRETO/TRUCO/OCULTO/etc |
| 9 | `tiene_ano` | Binaria | Contiene 2024/2025/2026 |
| 10 | `categoria_prioritaria` | Binaria | Es categor√≠a 22/26/27/28 |
| 11 | `canal_pequeno` | Binaria | Suscriptores < 100K |
| 12 | `frecuencia_buena` | Binaria | 3-7 d√≠as desde √∫ltimo video |

### Modelos del Ensemble

#### 1. Random Forest
```python
RandomForestRegressor(
    n_estimators=100,
    max_depth=7,              # Limita profundidad (anti-overfitting)
    min_samples_split=30,     # M√≠nimo 30 samples por split
    min_samples_leaf=10,
    max_features='sqrt',      # Solo sqrt(12) ‚âà 3-4 features por √°rbol
    random_state=42
)
```

#### 2. Gradient Boosting
```python
GradientBoostingRegressor(
    n_estimators=100,
    max_depth=6,              # M√°s conservador que RF
    min_samples_split=25,
    learning_rate=0.05,       # Aprendizaje lento (anti-overfitting)
    subsample=0.8,            # Bootstrap 80% (variabilidad)
    random_state=42
)
```

#### 3. Ridge Regression
```python
Ridge(
    alpha=10.0,               # Regularizaci√≥n L2 fuerte
    random_state=42
)
```

### Validaci√≥n

#### 1. TimeSeriesSplit Cross-Validation

```
Fold 1: [Train ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ] [Test]
Fold 2: [Train ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ] [Test]
Fold 3: [Train ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ] [Test]
Fold 4: [Train ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ] [Test]
Fold 5: [Train ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ] [Test]
```

- 5 folds temporales (NO aleatorios)
- Respeta orden cronol√≥gico
- Evita data leakage

#### 2. Hold-out Test Set

- 80% Train + 20% Test
- Test = Videos m√°s recientes (√∫ltimos en tiempo)
- NUNCA vistos durante entrenamiento

#### 3. Criterios de Aceptaci√≥n

Modelo se guarda SOLO si cumple:

| Criterio | Umbral | Descripci√≥n |
|----------|--------|-------------|
| **Precision** | >= 60% | Clasificaci√≥n correcta EXITOSO/PROMEDIO/FRACASO |
| **R¬≤ Score** | >= 0.20 | Al menos 20% de varianza explicada |
| **MAE** | Razonable | Error absoluto medio en VPH |

Si NO cumple:
- Modelo NO se guarda
- Se mantiene modelo anterior
- Email de alerta enviado
- Esperar al pr√≥ximo mes (m√°s datos)

### Clasificaci√≥n de VPH

| Clase | VPH | Acci√≥n |
|-------|-----|--------|
| **EXITOSO** üöÄ | >= 120 | PUBLICAR |
| **PROMEDIO** üü° | 60-119 | Revisar recomendaciones |
| **FRACASO** ‚ùå | < 60 | RE-PLANIFICAR |

---

## ‚ö†Ô∏è Anti-Patrones

El sistema detecta autom√°ticamente 10+ anti-patrones comunes:

### Timing

| Anti-Patr√≥n | Confianza | Impacto |
|-------------|-----------|---------|
| Publicar lunes/martes ma√±ana | ALTA | Muy Negativo |
| Publicar domingo noche | MEDIA | Negativo |
| Publicar madrugada (0-6AM) | ALTA | Muy Negativo |

### T√≠tulo

| Anti-Patr√≥n | Confianza | Impacto |
|-------------|-----------|---------|
| Sin palabras gancho | ALTA | Muy Negativo |
| T√≠tulo muy corto (<60 chars) | MEDIA | Negativo |
| Sin a√±o actual | MEDIA | Negativo |
| T√≠tulo muy largo (>105 chars) | BAJA | Leve Negativo |

### Nicho

| Anti-Patr√≥n | Confianza | Impacto |
|-------------|-----------|---------|
| Fuera del nicho principal (score <50) | ALTA | Muy Negativo |

### C√≥mo se Detectan

1. Cada domingo, analiza videos de √∫ltimos 7 d√≠as
2. Clasifica por VPH: EXITOSO/PROMEDIO/FRACASO
3. Analiza SOLO fracasos (VPH < 60)
4. Busca patrones comunes
5. Guarda en tabla `anti_patrones`
6. Genera reporte y email

### Ver Anti-Patrones

```sql
-- En Supabase SQL Editor
SELECT
    patron,
    frecuencia,
    confianza,
    impacto_vph_promedio,
    actualizado_at
FROM anti_patrones
ORDER BY frecuencia DESC
LIMIT 10;
```

---

## üîß Troubleshooting

### Error: "Modelo no encontrado"

```
[ERROR] Modelo no encontrado
[ERROR] Ruta: GITHUB CRON/models/predictor_ensemble.pkl
```

**Soluci√≥n:**
1. Entrenar modelo manualmente:
   ```bash
   cd scripts
   python train_predictor_model.py
   ```

2. Verificar que modelo fue aprobado:
   - Precision >= 60%?
   - Dataset >= 100 videos?

3. Si modelo no cumple criterios:
   - Esperar m√°s datos (pr√≥ximo mes)
   - Verificar calidad de datos en `ml_training_data`

### Error: "Dataset muy peque√±o"

```
[ERROR] Dataset muy peque√±o (42 samples)
[ERROR] Se recomienda >= 100 samples
```

**Soluci√≥n:**
1. Verificar que `save_training_snapshot.py` se ejecuta:
   ```bash
   python save_training_snapshot.py
   ```

2. Verificar datos en Supabase:
   ```sql
   SELECT COUNT(*) FROM ml_training_data;
   ```

3. Esperar a que se acumulen m√°s snapshots (cada 2 d√≠as + mensual)

4. Mientras tanto, usar dashboard para ver anti-patrones semanales

### Error: "Precisi√≥n muy baja (< 60%)"

```
‚ùå CRITERIO 1: Precision < 60% (42.3%)
```

**Causas comunes:**
1. Dataset muy peque√±o
2. Datos de mala calidad (VPH = 0)
3. Cambio algor√≠tmico de YouTube
4. Nicho muy vol√°til

**Soluci√≥n:**
1. Verificar calidad de datos:
   ```sql
   SELECT
       AVG(vph) as vph_promedio,
       COUNT(CASE WHEN vph = 0 THEN 1 END) as ceros,
       COUNT(*) as total
   FROM ml_training_data;
   ```

2. Si muchos ceros, revisar scripts de captura

3. Esperar al pr√≥ximo mes (m√°s datos = mejor modelo)

4. Modelo anterior se mantiene activo

### Error: GitHub Actions falla al commit modelo

```
ERROR: Permission denied (publickey)
```

**Soluci√≥n:**
1. Verificar que workflow tiene permisos:
   ```yaml
   permissions:
     contents: write
   ```

2. Verificar token en checkout:
   ```yaml
   - uses: actions/checkout@v4
     with:
       token: ${{ secrets.GITHUB_TOKEN }}
   ```

### Snapshot no guarda datos

```
[INFO] Videos sin captions: 0
```

**Verificar:**
1. ¬øHay videos en ventana de 23-30 d√≠as?
   ```sql
   SELECT COUNT(*)
   FROM video_shorts_search
   WHERE published_at >= NOW() - INTERVAL '30 days'
     AND published_at < NOW() - INTERVAL '23 days';
   ```

2. ¬øYa existen en ml_training_data?
   ```sql
   SELECT COUNT(*) FROM ml_training_data;
   ```

3. Si ventana vac√≠a: Normal, esperar a que videos lleguen a esa edad

---

## üìà Mejoras Futuras

### Fase 1 (Actual) ‚úÖ
- [x] Sistema b√°sico de predicci√≥n
- [x] 12 features limpias
- [x] Ensemble de 3 modelos
- [x] Validaci√≥n temporal
- [x] Anti-patrones semanales
- [x] 100% autom√°tico

### Fase 2 (Pr√≥xima)
- [ ] Detecci√≥n de drift algor√≠tmico
- [ ] Modelo espec√≠fico por tipo (shorts vs longs)
- [ ] Features de thumbnail (OCR + embeddings)
- [ ] An√°lisis de sentimiento de t√≠tulos
- [ ] Predicci√≥n de retenci√≥n

### Fase 3 (Avanzada)
- [ ] Transfer learning con BERT/GPT
- [ ] Predicci√≥n de monetizaci√≥n
- [ ] Recomendaciones de edici√≥n
- [ ] A/B testing automatizado

---

## üìù Notas Importantes

### Cuota API
- **Snapshot**: 0 unidades (solo lee Supabase)
- **Entrenamiento**: 0 unidades (solo lee Supabase)
- **An√°lisis semanal**: 0 unidades (solo lee Supabase)
- **Predicci√≥n**: 0 unidades (modelo local)

**TOTAL: 0 unidades API consumidas** ‚úÖ

### Almacenamiento
- `ml_training_data`: ~2KB por video
- 1,000 videos = 2 MB
- 10,000 videos = 20 MB
- Crecimiento: ~700 videos/mes = 1.4 MB/mes

**Plan Free (500 MB): Suficiente para ~250K videos** ‚úÖ

### Privacidad
- Todos los datos en tu Supabase privado
- Modelo entrenado localmente (GitHub Actions)
- NO se env√≠a nada a servicios externos
- Predicciones 100% offline

---

## üéØ Resultado Esperado

Con este sistema 100% autom√°tico:

1. **An√°lisis Continuo**:
   - Anti-patrones detectados cada semana
   - Alertas tempranas de problemas

2. **Predicciones Confiables**:
   - Precisi√≥n 65-80% esperada
   - Evita publicar videos con alto riesgo de fracaso
   - Optimiza timing y formato

3. **Aprendizaje Continuo**:
   - Modelo se actualiza cada mes
   - Se adapta a cambios del algoritmo de YouTube
   - Aprende de tus √©xitos Y fracasos

4. **Ahorro de Tiempo**:
   - NO m√°s videos que fracasan
   - Focus en contenido que funciona
   - Mejora continua autom√°tica

---

## üìû Soporte

Si encuentras problemas:

1. Revisar logs de GitHub Actions
2. Verificar tabla `modelo_ml_metadata` en Supabase
3. Ejecutar scripts manualmente para debugging
4. Revisar esta documentaci√≥n (Troubleshooting)

---

**ü§ñ Sistema ML Predictor v1.0**
Creado con Claude Code | √öltima actualizaci√≥n: 2025-11-10
